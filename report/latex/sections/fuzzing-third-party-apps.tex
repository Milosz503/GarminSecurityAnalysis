\chapter{Fuzzing third-party apps} \label{sec:fuzzing}
\section{Introduction}
Static analysis of assembly code is a very time-consuming process that requires extensive knowledge.
Without any documentation, source code provided by the vendor, or any other help, it is extremely difficult to understand the code.

For this reason, I decided to use dynamic analysis to find vulnerabilities in the code.
As I am focusing on analysis of the virtual machine in the simulator, there are more possibilities to test the behaviour during runtime.
The simulator allows running the code in a controlled environment, which makes it easier to test different scenarios.
With this approach, there is no need to understand the code.
It is also valuable when the code base is large and complex.
Additionally, instead of spending time on reverse engineering, it is possible to write a fuzzer that will do the difficult work.
Sometimes it might be necessary to run the fuzzer for a long time.
This, however, does not require any human interaction and can be scaled to run on multiple machines or threads.
The expected outcome of the fuzzer is a binary file that crashes the virtual machine and can be run on the watch.

Finding vulnerabilities in the simulator is aimed at achieving two potential objectives.
Firstly, it might be possible to escape the sandbox and execute arbitrary code on the host machine.
Secondly, vulnerabilities in the simulator might be present in the real device as well.

\section{Environment setup}
When fuzzing a program, the most basic configuration would be to have a fuzzer and provide it with a program and the starting input.
Then the fuzzer would run the program with different modifications of the input and check if it crashes.

However, in this case, the setup is more complicated.
Simulator is run a standalone program.
Then the application has to be loaded with an additional command line script.
As such, the fuzzer needs to be aware of both tools.

Moreover, when modifying the input, the virtual machine requires it to be signed.
This means that to test the execution after each modification, the input needs to be signed again.


\section{Fuzzing solutions}
One of the most popular fuzzing solutions is AFL++\cite{aflplusplus}.
It is an improved fork to Google's AFL\footnote{\url{https://github.com/google/AFL}}, which is no longer maintained.
AFL++ is an open-source tool for fuzzing a wide range of software.
It is coupled with instrumentation-guided genetic algorithm, having a possibility to be extended for different use cases.

\section{Fuzzing process}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\linewidth]{../../images/fuzzer-diagram}
    \caption{Fuzzing process}
    \label{fig:fuzzer-diagram}
\end{figure}

The fuzzer consists of four main components: Mutator, Simulator, MonkeyDo, and Oracle, as presented in Figure~\ref{fig:fuzzer-diagram}.
The fuzzing is performed in an iterative manner.
The Mutator generates a new input, then Oracle tests the execution of the input.
Based on the result, the Mutator either mutates the current input or reverts the previous mutation.
This way, the input oscillates closely between two states: one that barely works and another one that does not run successfully.
With this continuous modification of the input, the fuzzer explores different variations of the bytecode until it finds one that is not handled correctly by the virtual machine.
To make it possible to reproduce the steps, the fuzzer uses a random generator with a fixed seed, defined at the beginning of the script.


\subsection*{Mutator}
\begin{lstlisting}[caption={Pseudocode of the mutating algorithm},captionpos=b,label={lst:mutator},language=Python]
originalApp = load("seed_app.prg")
currentApp = originalApp
lastMutation = emptyList()

def mutate(passed: Boolean):
    if passed:
        mutateCurrentApp()
    else:
        revertMutations()
    return sign(currentApp)

def mutateCurrentApp():
    mutation = generateMutation()
    for byte in mutation:
        currentApp[byte] = flipRandomBit(currentApp[byte])
    lastMutation = mutation

def revertMutations():
    lastMutation, bytesToRevert = splitInHalf(lastMutation)
    for byte in bytesToRevert:
        currentApp[byte] = originalApp[byte]

def generateMutation():
    mutationSize = mutationRate*len(currentApp)
    return [randomByte() for i in range(0, mutationSize)]
\end{lstlisting}

Mutator is responsible for generating a new input for the simulator.
It does that by mutating the original(seed) application and signing it again as described in section~\ref{sec:modifying-the-executable}.
The pseudocode of the mutating algorithm is presented in Listing~\ref{lst:mutator}.
Depending on the result of the previous execution, the mutator either mutates the current application or reverts the previous mutation.
To make the process more efficient, the mutator does not revert the whole mutation, but only half of it.
Using the divide-and-conquer approach, it is possible to find the byte that broke the application faster.


\subsection*{Simulator}
%\begin{figure}
%    \centering
    \begin{figure}[b]
        \centering
        \includegraphics[width=0.39\linewidth]{../../images/simulator-seed-app}
        \caption{Simulator running seed app}
        \label{fig:simulator-seed-app}
    \end{figure}
    \begin{figure}
        \centering
        \includegraphics[width=0.6\linewidth]{../../images/simulator-signature-failed}
        \caption{Simulator output when signature verification fails}
        \label{fig:simulator-signature-failed}
    \end{figure}
%    \caption{Simulator}
%\end{figure}
The simulator component is responsible for running the simulator executable.
In Figure~\ref{fig:simulator-seed-app}, the simulator is running the seed application.
The component monitors the output of the simulator, which can be used by the Oracle to decide if provided input has been executed successfully.
This information is needed to decide if the mutator should mutate the current application or revert the previous mutation.
Example output of the simulator is presented in Figure~\ref{fig:simulator-signature-failed}.
Additionally, the component detects when the simulator crashes.
This information is used by the Oracle component to determine if a bug has been found.

\subsection*{MonkeyDo}
Oracle component is using MonkeyDo script to load the application into the simulator.
The script outputs logs from the loaded application.
It also does a partial parsing of the application and might sometimes output errors.


\subsection*{Oracle}
The Oracle component tests the execution of the application generated by the Mutator.
It uses the output of the Simulator and MonkeyDo to determine if the execution was successful.
At this stage, it was important to investigate possible outputs of the MonkeyDo script and the simulator.
Based on those outputs, a decision is made if the application should be mutated or reverted.

The app is programmed to print a message $Okay$ when it is executed.
This message is used to determine if the execution was successful.
However, it may take a few seconds for the message to appear.
To speed up the process, the Oracle also checks if any of the expected error messages has been printed.
If it is the case, the execution is considered to be unsuccessful.

Sometimes when the application is modified, the simulator will output an error message that signature check failed.
The message contains the name of the app file.
When this happens, the application is considered invalid and the mutation is reverted.
However, sometimes the same output is produced again when the next application is loaded.
Because of that, every version of the application has to have a different file name.
This way, it can be determined if the error is caused by the previous application or the current one.


\section{Fuzzing results}

For the fuzzing, I created a simple application that prints a message $Okay$ when executed.
The application is based on an example provided by the SDK, called $Confirmation Dialog$.

I was running the fuzzer with at most 50 iterations, so that it would be possible to easily reproduce all the steps.
Each run of the fuzzer started with a different seed for random generator.

After the first run, I noticed that sometimes there would be an error message: $Permissions required$.
Probably some of the modifications caused the application to access parts of the SDK that it did not have permission to.
As such, I decided to modify the application to request all permissions.
This way, it would be possible to detect potential bugs in all parts of the SDK\@.

With this configuration, the fuzzer was able to find an input that caused the simulator to crash.
Roughly every second or third run of the fuzzer a new input was found.
The crash was caused by a segmentation fault, as presented in Figure~\ref{fig:simulator-crash}.
This is a bug in the simulator, as it should not crash when executing an application.
However, it is difficult to assess if this bug can be exploited.
Potentially, it might be possible to execute arbitrary code on the host machine.
However, it would require a further investigation.

Additionally, during the fuzzing, I noticed a weird behaviour of the simulator.
Once, when the application was executed, the simulator opened a window with a profiler, as presented in Figure~\ref{fig:simulator-bug-profiler}.



\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\linewidth]{../../images/simulator-crash}
    \caption{Simulator crash}
    \label{fig:simulator-crash}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{../../images/simulator-bug-profiler}
    \caption{Weird simulator behaviour}
    \label{fig:simulator-bug-profiler}
\end{figure}